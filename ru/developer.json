{
  "tabs/server": "Локальный сервер",
  "tabs/extensions": "LM Runtimes",
  "loadSettings/title": "Загрузить настройки",
  "modelSettings/placeholder": "Выберите модель для настройки",
  "loadedModels/noModels": "Модели не загружены",
  "serverOptions/title": "Параметры сервера",
  "serverOptions/configurableTitle": "Настройки",
  "serverOptions/port/hint": "Выберите сетевой порт, который будет использовать локальный сервер. По умолчанию LM Studio использует порт 1234. Возможно, вам потребуется изменить этот порт, если он уже используется.",
  "serverOptions/port/subtitle": "Порт для прослушивания",
  "serverOptions/autostart/title": "Автоматический старт сервера",
  "serverOptions/autostart/hint": "Автоматически запускать локальный сервер при загрузке модели",
  "serverOptions/port/integerWarning": "Номер порта должен быть целым числом",
  "serverOptions/port/invalidPortWarning": "Порт должен быть в диапазоне от 1 до 65535",
  "serverOptions/cors/title": "Включить CORS",
  "serverOptions/cors/hint1": "Включение CORS (Cross-origin Resource Sharing) позволит сайтам, которые вы посещаете, делать запросы к серверу LM Studio.",
  "serverOptions/cors/hint2": "CORS может понадобиться при выполнении запросов с веб-страницы или с помощью VS Code / других расширений.",
  "serverOptions/cors/subtitle": "Разрешить запросы с других сайтов",
  "serverOptions/network/title": "Служить в локальной сети",
  "serverOptions/network/subtitle": "Обеспечить доступ к серверу с устройств локальной сети",
  "serverOptions/network/hint1": "Разрешить подключения с других устройств в сети.",
  "serverOptions/network/hint2": "Если не отмечено, сервер будет прослушивать только localhost.",
  "serverOptions/verboseLogging/title": "Подробное логирование",
  "serverOptions/verboseLogging/subtitle": "Включить подробное логирование для локального сервера",
  "serverOptions/contentLogging/title": "Логирование запросов и ответов",
  "serverOptions/contentLogging/subtitle": "Настройки логирования запросов и ответов локального сервера",
  "serverOptions/contentLogging/hint": "Включить логирование запросов и/или ответов в лог файл локального сервера.",
  "serverOptions/jitModelLoading/title": "Загрузка модели по требованию",
  "serverOptions/jitModelLoading/hint": "При включенном режиме, если запрос указывает модель, которая не загружена, она будет автоматически загружена и использована. Кроме того, эндпоинт \"/v1/models\" также будет включать модели, которые еще не были загружены.",
  "serverOptions/loadModel/error": "Не удалось загрузить модель",
  "serverLogs/scrollToBottom": "Перейти вниз",
  "serverLogs/clearLogs": "Очистить логи ({{shortcut}})",
  "serverLogs/openLogsFolder": "Открыть папку с логами сервера",
  "runtimeSettings/title": "Настройки среды выполнения",
  "runtimeSettings/chooseRuntime/title": "Настроить среды выполнения",
  "runtimeSettings/chooseRuntime/description": "Выберите среду выполнения для каждой модели",
  "runtimeSettings/chooseRuntime/showAllVersions/label": "Показать все версии",
  "runtimeSettings/chooseRuntime/showAllVersions/hint": "По умолчанию, LM Studio показывает только последнюю версию каждой совместимой среды выполнения. Включите эту опцию, чтобы увидеть все доступные среды выполнения.",
  "runtimeSettings/chooseRuntime/select/placeholder": "Выбрать среду выполнения",
  "runtimeOptions/uninstall": "Удалить",
  "runtimeOptions/uninstallDialog/title": "Удалить {{runtimeName}}?",
  "runtimeOptions/uninstallDialog/body": "Удаление этой среды выполнения приведет к её удалению с системы. Это действие необратимо.",
  "runtimeOptions/uninstallDialog/body/caveats": "Некоторые файлы могут быть удалены только после перезапуска LM Studio.",
  "runtimeOptions/uninstallDialog/error": "Не удалось удалить среду выполнения",
  "runtimeOptions/uninstallDialog/confirm": "Продолжить и удалить",
  "runtimeOptions/uninstallDialog/cancel": "Отмена",
  "runtimeOptions/noCompatibleRuntimes": "Совместимые среды выполнения не найдены",
  "runtimeOptions/downloadIncompatibleRuntime": "Эта среда выполнения была определена как несовместимая с вашим компьютером. Вероятно, она не будет работать.",
  "runtimeOptions/noRuntimes": "Среды выполнения не найдены",
  "inferenceParams/noParams": "Для этого типа модели недоступны настраиваемые параметры предсказания",
  "endpoints/openaiCompatRest/title": "Поддерживаемые эндпоинты (похожи на OpenAI)",
  "endpoints/openaiCompatRest/getModels": "Список текущих загруженных моделей",
  "endpoints/openaiCompatRest/postCompletions": "Режим текстовых дополнений. Предскажите следующий токен(ы) по запросу. Примечание: OpenAI считает этот эндпоинт 'устаревшим'.",
  "endpoints/openaiCompatRest/postChatCompletions": "Дополнения для чата. Отправьте историю чата модели, чтобы предсказать следующий ответ ассистента",
  "endpoints/openaiCompatRest/postEmbeddings": "Текстовые вложения. Создайте вложения текста для заданного текстового ввода. Принимает строку или массив строк.",
  "model.createVirtualModelFromInstance": "Сохранить настройки как новую виртуальную модель",
  "model.createVirtualModelFromInstance/error": "Не удалось сохранить настройки как новую виртуальную модель",
  "apiConfigOptions/title": "Конфигурация API"
}